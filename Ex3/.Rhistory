ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 100, alpha = 0.6, position = "identity") +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
library(ggplot2)
library(scales)
library(readxl)
library(stats)
econ <- read_excel("Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex1/econ.xlsx",
col_types = c("skip", "skip", "skip",
"numeric", "skip", "numeric"))
tpp <- econ$tpp
z_tpp <- (tpp - mean(tpp)) / sd(tpp)
ndesemp <- econ$ndesemp
z_ndesemp <- (ndesemp - mean(ndesemp)) / sd(ndesemp)
multi <- data.frame(
Parametros = rep(c("z_tpp", "z_ndesemp"), each = length(tpp)),
Ozono = c(z_tpp, z_ndesemp)
)
ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 100, alpha = 0.6, position = "identity", width = 0.6) +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
library(ggplot2)
library(scales)
library(readxl)
library(stats)
econ <- read_excel("Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex1/econ.xlsx",
col_types = c("skip", "skip", "skip",
"numeric", "skip", "numeric"))
tpp <- econ$tpp
z_tpp <- (tpp - mean(tpp)) / sd(tpp)
ndesemp <- econ$ndesemp
z_ndesemp <- (ndesemp - mean(ndesemp)) / sd(ndesemp)
multi <- data.frame(
Parametros = rep(c("z_tpp", "z_ndesemp"), each = length(tpp)),
Ozono = c(z_tpp, z_ndesemp)
)
ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 100, alpha = 0.6, position = "identity") +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
library(ggplot2)
library(scales)
library(readxl)
library(stats)
econ <- read_excel("Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex1/econ.xlsx",
col_types = c("skip", "skip", "skip",
"numeric", "skip", "numeric"))
tpp <- econ$tpp
z_tpp <- (tpp - mean(tpp)) / sd(tpp)
ndesemp <- econ$ndesemp
z_ndesemp <- (ndesemp - mean(ndesemp)) / sd(ndesemp)
multi <- data.frame(
Parametros = rep(c("z_tpp", "z_ndesemp"), each = length(tpp)),
Ozono = c(z_tpp, z_ndesemp)
)
ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 75, alpha = 0.6, position = "identity") +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
install.packages(rio)
install.packages(rio)
library(rio)
install_formats(rio)
install_formats(rio)
install.packages(rio)
library(rio)
library(rio)
library(rio)
library(rio)
library(ggplot2)
library(rio)
library(scales)
library(readxl)
library(stats)
econ <- read_excel("Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex1/econ.xlsx",
col_types = c("skip", "skip", "skip",
"numeric", "skip", "numeric"))
tpp <- econ$tpp
z_tpp <- (tpp - mean(tpp)) / sd(tpp)
ndesemp <- econ$ndesemp
z_ndesemp <- (ndesemp - mean(ndesemp)) / sd(ndesemp)
multi <- data.frame(
Parametros = rep(c("z_tpp", "z_ndesemp"), each = length(tpp)),
Ozono = c(z_tpp, z_ndesemp)
)
ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 75, alpha = 0.6, position = "identity") +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
library(rio)
urlmy<-"https://web.tecnico.ulisboa.pt/~ist13493/PE_aulas2023/R_Material_exerciciosR/ex1.xlsx"
library(rio)
install_formats()
library(rio)
library(scales)
library(stats)
econ <- read_excel("Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex1/econ.xlsx",
col_types = c("skip", "skip", "skip",
"numeric", "skip", "numeric"))
tpp <- econ$tpp
z_tpp <- (tpp - mean(tpp)) / sd(tpp)
ndesemp <- econ$ndesemp
z_ndesemp <- (ndesemp - mean(ndesemp)) / sd(ndesemp)
multi <- data.frame(
Parametros = rep(c("z_tpp", "z_ndesemp"), each = length(tpp)),
Ozono = c(z_tpp, z_ndesemp)
)
ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 75, alpha = 0.6, position = "identity") +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
library(ggplot2)
library(rio)
library(scales)
library(stats)
econ <- read_excel("Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex1/econ.xlsx",
col_types = c("skip", "skip", "skip",
"numeric", "skip", "numeric"))
tpp <- econ$tpp
z_tpp <- (tpp - mean(tpp)) / sd(tpp)
ndesemp <- econ$ndesemp
z_ndesemp <- (ndesemp - mean(ndesemp)) / sd(ndesemp)
multi <- data.frame(
Parametros = rep(c("z_tpp", "z_ndesemp"), each = length(tpp)),
Ozono = c(z_tpp, z_ndesemp)
)
ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 75, alpha = 0.6, position = "identity") +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
library(ggplot2)
library(rio)
library(scales)
library(stats)
econ <- read_excel("Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex1/econ.xlsx",
col_types = c("skip", "skip", "skip",
"numeric", "skip", "numeric"))
tpp <- econ$tpp
z_tpp <- (tpp - mean(tpp)) / sd(tpp)
ndesemp <- econ$ndesemp
z_ndesemp <- (ndesemp - mean(ndesemp)) / sd(ndesemp)
multi <- data.frame(
Parametros = rep(c("z_tpp", "z_ndesemp"), each = length(tpp)),
Ozono = c(z_tpp, z_ndesemp)
)
ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 50, alpha = 0.6, position = "identity") +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
econ <- read_excel("Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex1/econ.xlsx",
col_types = c("skip", "skip", "skip",
"numeric", "skip", "numeric"))
tpp <- econ$tpp
z_tpp <- (tpp - mean(tpp)) / sd(tpp)
ndesemp <- econ$ndesemp
z_ndesemp <- (ndesemp - mean(ndesemp)) / sd(ndesemp)
multi <- data.frame(
Parametros = rep(c("z_tpp", "z_ndesemp"), each = length(tpp)),
Ozono = c(z_tpp, z_ndesemp)
)
ggplot(multi, aes(x = Ozono, fill = Parametros)) +
geom_histogram(bins = 50, alpha = 0.6, position = "identity") +
labs(x = expression("Quantidade de Ozono por metro cúbico ug/m"^3),
y = "Frequência")
set.seed(1840)
n <- 1192
p <- 0.35
sample <- numeric(n)
# Simulação da distribuição geométrica de parâmetro p
for (i in 1:n) {
u <- runif(1)
x <- floor(log(1 - u) / log(1 - p))
sample[i] <- x
}
# Cálculo da média e do desvio padrão amostrais
mean <- mean(sample)
std <- sd(sample)
# Cálculo da soma da média com o desvio padrão amostrais
sum_mean_std <- mean + std
# Contagem dos valores simulados superiores à soma da média com o desvio padrão amostrais
count <- sum(sample > sum_mean_std)
# Cálculo da proporção
proportion <- count / n
print(paste("A proporção é:", round(proportion, 4)))
set.seed(1840)
n <- 1192
p <- 0.35
sample <- numeric(n)
# Simulação da distribuição geométrica de parâmetro p
for (i in 1:n) {
u <- runif(1)
x <- floor(log(1 - u) / log(1 - p))
sample[i] <- x
}
# Cálculo da média e do desvio padrão amostrais
mean <- mean(sample)
std <- sd(sample)
# Cálculo da soma da média com o desvio padrão amostrais
sum_mean_std <- mean + std
# Contagem dos valores simulados superiores à soma da média com o desvio padrão amostrais
count <- sum(sample > sum_mean_std)
# Cálculo da proporção
proportion <- count / n
print(paste("A proporção é:", round(proportion, 4)))
set.seed(1840)
n <- 1192
p <- 0.35
sample <- numeric(n)
# Simulação da distribuição geométrica de parâmetro p
for (i in 1:n) {
u <- runif(1)
x <- floor(log(1 - u) / log(1 - p))
sample[i] <- x
}
# Cálculo da média e do desvio padrão amostrais
mean <- mean(sample)
std <- sd(sample)
# Cálculo da soma da média com o desvio padrão amostrais
sum_mean_std <- mean + std
# Contagem dos valores simulados superiores à soma da média com o desvio padrão amostrais
count <- sum(sample > sum_mean_std)
# Cálculo da proporção
proportion <- count / n
print(paste("A proporção é:", round(proportion, 4)))
set.seed(1616)
sample_sizes <- c(30, 50, 100, 200, 300, 500, 1000)
num_samples <- 1000
p <- 0.2
conf_level <- 0.96
z <- qnorm((1 + conf_level)/2)
average_diff <- numeric(length(sample_sizes))
for (i in 1:length(sample_sizes)) {
n <- sample_sizes[i]
diff_lengths <- numeric(num_samples)
for (j in 1:num_samples) {
sample <- rbinom(n, 1, p)
sample_mean <- mean(sample)
# Method 1
grid_search <- function(p, sample_mean, n, z) {
abs(sample_mean^2 - 2*sample_mean*p + p^2 - z^2*p*(1-p)/n)
}
p_vals <- seq(0, 1, 0.001)
diffs <- sapply(p_vals, grid_search, sample_mean=sample_mean, n=n, z=z)
p_lower1 <- p_vals[which.min(diffs[1:floor(length(diffs)/2)])]
p_upper1 <- p_vals[which.min(diffs[(floor(length(diffs)/2)+1):length(diffs)]) + floor(length(diffs)/2)]
# Method 2
se <- sqrt(sample_mean * (1-sample_mean) / n)
p_lower2 <- sample_mean - z*se
p_upper2 <- sample_mean + z*se
# Difference in lengths
diff_lengths[j] <- (p_upper2 - p_lower2) - (p_upper1 - p_lower1)
}
average_diff[i] <- mean(diff_lengths)
}
# Plot the result
plot(sample_sizes, average_diff, type = "b", lwd = 2,
xlab = "Sample size", ylab = "Average difference in lengths",
main = "Difference between the methods")
set.seed(1918)
tamanho_amostra <- c(30, 50, 100, 200, 300, 500, 1000)
k <- 3000
p <- 0.6
nivel_conf <- 0.93
z <- qnorm((1 + nivel_conf)/2)
dif_media <- numeric(length(tamanho_amostra))
for (i in 1:length(tamanho_amostra)) {
n <- tamanho_amostra[i]
dif_comp <- numeric(k)
for (j in 1:k) {
amostra <- rbinom(n, 1, p)
amostra_media <- mean(amostra)
# Method 1
proc <- function(p, amostra_media, n, z) {
abs(amostra_media^2 - 2*amostra_media*p + p^2 - z^2*p*(1-p)/n)
}
p_valores <- seq(0, 1, 0.001)
diferenca <- sapply(p_valores, proc, amostra_media=amostra_media, n=n, z=z)
p_bai1 <- p_valores[which.min(diferenca[1:floor(length(diferenca)/2)])]
p_cim1 <- p_valores[which.min(diferenca[(floor(length(diferenca)/2)+1):length(diferenca)]) + floor(length(diferenca)/2)]
# Method 2
se <- sqrt(amostra_media * (1-amostra_media) / n)
p_bai2 <- amostra_media - z*se
p_cim2 <- amostra_media + z*se
# Difference in lengths
dif_comp[j] <- (p_cim2 - p_bai2) - (p_cim1 - p_bai1)
}
dif_media[i] <- mean(dif_comp)
}
# Plot the result
plot(tamanho_amostra, dif_media, type = "b", lwd = 2,
xlab = "Tamanho da amostra", ylab = "diferença entre a média de comprimentos",
main = "Diferência entre os métodos")
set.seed(1918)
tamanho_amostra <- c(30, 50, 100, 200, 300, 500, 1000)
k <- 3000
p <- 0.6
nivel_conf <- 0.93
z <- qnorm((1 + nivel_conf)/2)
dif_media <- numeric(length(tamanho_amostra))
for (i in 1:length(tamanho_amostra)) {
n <- tamanho_amostra[i]
dif_comp <- numeric(k)
for (j in 1:k) {
amostra <- rbinom(n, 1, p)
amostra_media <- mean(amostra)
# Metodo 1
proc <- function(p, amostra_media, n, z) {
abs(amostra_media^2 - 2*amostra_media*p + p^2 - z^2*p*(1-p)/n)
}
p_valores <- seq(0, 1, 0.001)
diferenca <- sapply(p_valores, proc, amostra_media=amostra_media, n=n, z=z)
p_bai1 <- p_valores[which.min(diferenca[1:floor(length(diferenca)/2)])]
p_cim1 <- p_valores[which.min(diferenca[(floor(length(diferenca)/2)+1):length(diferenca)]) + floor(length(diferenca)/2)]
# Metodo 2
se <- sqrt(amostra_media * (1-amostra_media) / n)
p_bai2 <- amostra_media - z*se
p_cim2 <- amostra_media + z*se
dif_comp[j] <- (p_cim2 - p_bai2) - (p_cim1 - p_bai1)
}
dif_media[i] <- mean(dif_comp)
}
plot(tamanho_amostra, dif_media, type = "b", lwd = 2,
xlab = "Tamanho da amostra", ylab = "Diferenças médias",
main = "Diferência entre os métodos")
set.seed(1918)
tamanho_amostra <- c(30, 50, 100, 200, 300, 500, 1000)
k <- 3000
p <- 0.6
nivel_conf <- 0.93
z <- qnorm((1 + nivel_conf)/2)
dif_media <- numeric(length(tamanho_amostra))
for (i in 1:length(tamanho_amostra)) {
n <- tamanho_amostra[i]
dif_comp <- numeric(k)
for (j in 1:k) {
amostra <- rbinom(n, 1, p)
amostra_media <- mean(amostra)
# Metodo 1
proc <- function(p, amostra_media, n, z) {
abs(amostra_media^2 - 2*amostra_media*p + p^2 - z^2*p*(1-p)/n)
}
p_valores <- seq(0, 1, 0.001)
diferenca <- sapply(p_valores, proc, amostra_media=amostra_media, n=n, z=z)
p_bai1 <- p_valores[which.min(diferenca[1:floor(length(diferenca)/2)])]
p_cim1 <- p_valores[which.min(diferenca[(floor(length(diferenca)/2)+1):length(diferenca)]) + floor(length(diferenca)/2)]
# Metodo 2
se <- sqrt(amostra_media * (1-amostra_media) / n)
p_bai2 <- amostra_media - z*se
p_cim2 <- amostra_media + z*se
dif_comp[j] <- (p_cim2 - p_bai2) - (p_cim1 - p_bai1)
}
dif_media[i] <- mean(dif_comp)
}
plot(tamanho_amostra, dif_media, type = "b", lwd = 2,
xlab = "Tamanho da amostra", ylab = "Diferenças médias",
main = "Diferênça entre os métodos")
set.seed(1918)
tamanho_amostra <- c(30, 50, 100, 200, 300, 500, 1000)
k <- 3000
p <- 0.6
nivel_conf <- 0.93
z <- qnorm((1 + nivel_conf)/2)
dif_media <- numeric(length(tamanho_amostra))
for (i in 1:length(tamanho_amostra)) {
n <- tamanho_amostra[i]
dif_comp <- numeric(k)
for (j in 1:k) {
amostra <- rbinom(n, 1, p)
amostra_media <- mean(amostra)
# Metodo 1
proc <- function(p, amostra_media, n, z) {
abs(amostra_media^2 - 2*amostra_media*p + p^2 - z^2*p*(1-p)/n)
}
p_valores <- seq(0, 1, 0.001)
diferenca <- sapply(p_valores, proc, amostra_media=amostra_media, n=n, z=z)
p_bai1 <- p_valores[which.min(diferenca[1:floor(length(diferenca)/2)])]
p_cim1 <- p_valores[which.min(diferenca[(floor(length(diferenca)/2)+1):length(diferenca)]) + floor(length(diferenca)/2)]
# Metodo 2
se <- sqrt(amostra_media * (1-amostra_media) / n)
p_bai2 <- amostra_media - z*se
p_cim2 <- amostra_media + z*se
dif_comp[j] <- (p_cim2 - p_bai2) - (p_cim1 - p_bai1)
}
dif_media[i] <- mean(dif_comp)
}
plot(tamanho_amostra, dif_media, type = "b", lwd = 2,
xlab = "Tamanho da amostra", ylab = "Diferenças médias",
main = "Diferença entre os métodos")
set.seed(1718)
m <- 2744
n <- 13
sample_sumsquares <- numeric(m)
# Simulação das amostras e cálculo da soma dos quadrados
for (i in 1:m) {
sample <- rnorm(n)
sample_sumsquares[i] <- sum(sample^2)
}
# Cálculo do quantil de probabilidade 0.39 da amostra das somas dos quadrados
quantile_sample <- quantile(sample_sumsquares, probs = 0.39, type = 2)
# Cálculo do quantil correspondente à distribuição teórica
quantile_theoretical <- qchisq(0.39, df = n)
# Diferença em valor absoluto entre os quantis
difference <- abs(quantile_sample - quantile_theoretical)
print(paste("A diferença em valor absoluto é:", round(difference, 4)))
set.seed(1718)  # Define a semente como 1718
m <- 2744  # Número de amostras
n <- 13  # Dimensão das amostras
# Gerar amostras de uma população normal de média zero e variância unitária
samples <- matrix(rnorm(m * n), nrow = m, ncol = n)
# Calcular a soma dos quadrados dos valores observados para cada amostra
sum_of_squares <- rowSums(samples^2)
# Calcular o quantil de probabilidade 0.39 da amostra das somas dos quadrados dos valores observados
quantile_sample <- quantile(sum_of_squares, probs = 0.39, type = 2)
# Calcular o quantil correspondente à distribuição teórica da soma de quadrados de variáveis normais reduzidas independentes
quantile_theoretical <- qchisq(0.39, df = n)
# Calcular a diferença absoluta entre os dois quantis
diferenca <- abs(quantile_sample - quantile_theoretical)
diferenca <- round(diferenca, 4)  # Arredondar para 4 casas decimais
# Imprimir a diferença absoluta
print(diferenca)
set.seed(1718)  # Define a semente como 1718
m <- 2744  # Número de amostras
n <- 13  # Dimensão das amostras
# Gerar amostras de uma população normal de média zero e variância unitária
samples <- matrix(rnorm(m * n), nrow = m, ncol = n)
# Calcular a soma dos quadrados dos valores observados para cada amostra
sum_of_squares <- apply(samples, 1, function(x) sum(x^2))
# Calcular o quantil de probabilidade 0.39 da amostra das somas dos quadrados dos valores observados
quantile_sample <- quantile(sum_of_squares, probs = 0.39, type = 2)
# Calcular o quantil correspondente à distribuição teórica da soma de quadrados de variáveis normais reduzidas independentes
quantile_theoretical <- qchisq(0.39, df = n)
# Calcular a diferença em valor absoluto entre os dois quantis
diferenca <- abs(quantile_sample - quantile_theoretical)
diferenca <- round(diferenca, 4)  # Arredondar para 4 casas decimais
# Imprimir a diferença em valor absoluto
print(diferenca)
set.seed(1718)
m <- 2744
n <- 13
# Simular m amostras de dimensão n de uma população normal de média nula e variância unitária
amostras <- replicate(m, rnorm(n))
# Calcular a soma dos quadrados dos valores observados para cada amostra
somas_quadrados <- colSums(amostras^2)
# Calcular o quantil de probabilidade 0.59 da amostra das somas dos quadrados dos valores observados
quantil_amostra <- quantile(somas_quadrados, probs = 0.39, type = 2)
# Calcular o quantil de probabilidade 0.59 da distribuição teórica (qui-quadrado com n graus de liberdade)
quantil_teorico <- qchisq(0.39, df = n)
# Calcular a diferença em valor absoluto entre os dois quantis e arredondar para 4 casas decimais
diferenca <- round(abs(quantil_amostra - quantil_teorico), 4)
diferenca
# 1. Calcular a probabilidade de X = 5 ou 6
P_X_5 <- log10(1 + 1/4)
P_X_6 <- log10(1 + 1/7)
P_X_5_ou_6 <- P_X_5 + P_X_6
# 2. Obter a fração de potências de dois no intervalo [2^2, 2^28] com o primeiro algarismo 5 ou 6
potencias_de_dois <- 2^(6:22)
primeiro_algarismo <- as.integer(substr(potencias_de_dois, 1, 1))
potencias_de_dois_5_ou_6 <- length(which(primeiro_algarismo %in% c(4, 7)))
frac_potencias_de_dois_5_ou_6 <- potencias_de_dois_5_ou_6 / length(potencias_de_dois)
# 3. Calcular o desvio absoluto entre os valores calculados em 1. e 2.
desvio_absoluto <- abs(P_X_5_ou_6 - frac_potencias_de_dois_5_ou_6)
# 4. Indicar este desvio arredondado a 4 casas decimais.
desvio_absoluto <- round(desvio_absoluto, 4)
P_X_5_ou_6
frac_potencias_de_dois_5_ou_6
desvio_absoluto
set.seed(2842)
k <- 2877
lambda <- 25
# Step 1: Generate the exponential sample
sample <- rexp(k, rate = 1/lambda)
# Step 2: Calculate the cumulative sums and the total time
cumulative_sums <- cumsum(sample)
T <- ceiling(cumulative_sums[k])
# Step 3: Divide the interval into subintervals and count the number of events per subinterval
interval_width <- 1
num_subintervals <- ceiling(T / interval_width)
event_counts <- tabulate(floor(cumulative_sums / interval_width), nbins = num_subintervals)
# Step 4: Calculate the mean and absolute deviation
mean_events <- mean(event_counts)
expected_events <- lambda * interval_width
absolute_deviation <- abs(mean_events - expected_events)
rounded_deviation <- round(absolute_deviation, 4)
rounded_deviation
library(ggplot2)
# Leitura dos dados do arquivo
dados <- read.csv("GENDER_EMP_19032023152556091.txt", sep = "\t", header = TRUE)
setwd("~/Desktop/IST/Probabilidades e Estatística/ProjetoPE2023/Ex3")
library(ggplot2)
# Leitura dos dados do arquivo
dados <- read.csv("GENDER_EMP_19032023152556091.txt", sep = "\t", header = TRUE)
filtered_data <- subset(dados, Country == "New Zealand" & IND == "EMP3" & Age.Group %in% c("15-24", "25-54", "55-64") & TIME == 2015)
# Criar o gráfico de barras
ggplot(filtered_data, aes(x = Age.Group, y = Value, fill = SEX)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Idades", y = "Taxa de desemprego (%)", fill = "Sexo") +
scale_fill_manual(labels = c("Todos", "Homens", "Mulheres"), values = c("gray", "blue", "pink")) +
ggtitle("Taxa de Desemprego na Nova Zelândia (2015)") +
theme_minimal()
library(ggplot2)
# Leitura dos dados do arquivo
dados <- read.csv("GENDER_EMP_19032023152556091.txt", sep = "\t", header = TRUE)
filtered_data <- subset(dados, Country == "New Zealand" & IND == "EMP3" & Age.Group %in% c("15-24", "25-54", "55-64") & TIME == 2015)
# Criar o gráfico de barras
ggplot(filtered_data, aes(x = Age.Group, y = Value, fill = SEX)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Idades", y = "Taxa de desemprego (%)", fill = "Sexo") +
scale_fill_manual(labels = c("Todos", "Homens", "Mulheres"), values = c("gray", "blue", "pink")) +
ggtitle("Taxa de Desemprego na Nova Zelândia (2015)") +
theme_minimal()
